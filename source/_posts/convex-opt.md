---
title: 给你解惑凸优化、梯度下降和牛顿法
date: 2017-07-28 15:53:55
tags: [convex optimization,gradient descent,newton's method]
categories: machine learning
---
记得我在和优男一起研究Logistic Regression的时候，他问了我几个非常尖锐的问题，让我顿时哑口无言？
* 为什么Logistic Regression可以使用通过gradient optimization找到局部最优
* 为什么Logistic Regression还可以用Newton's method呢？
* Newton's method中Hessian matrix必须positive definite有什么意义呢，Logistic cost function能保证吗？

这些细节问题，说实话我也没有认真的想过。在夸奖他之余，我们也一起开始了研究，希望从中学习到一些更深层的东西，趁着现在有个blog分享给大家

### 凸优化(Convex optimization)

### 梯度下降法(Gradient descent)

### 牛顿法(Newton's method)